# Multicollinearity - detecion and remedies

Collinearity (and Multicollinearity) means that the predictors variables, also known as independent variables, aren’t so independent.

Collinearity is a situation where two features are linearly associated (high correlated), and they are used as predictors for the target. It’s often measured using Pearson’s correlation coefficient. Collinearity between more than two predictors is also possible (and often the case).

The term multicollinearity was first used by Ragnar Frisch. Multicollinearity is a special case of collinearity where a feature exhibits a linear relationship with two or more features. We can also have a situation where more than two features are correlated and, at the same time, have no high correlation pairwise.

Partial multicollinearity is ubiquitous in multiple regression. Two random variables will almost always correlate at some level in a sample, even if they share no fundamental relationship in the larger population. In other words, multicollinearity is a matter of degree.
